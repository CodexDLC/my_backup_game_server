# game_server/Logic/ApplicationLogic/world_orchestrator/runtime/handlers/auto_exploring_handler.py

import uuid
from typing import Dict, Any
import logging # –î–æ–±–∞–≤–ª–µ–Ω–æ –¥–ª—è —Ç–∏–ø–∏–∑–∞—Ü–∏–∏ –ª–æ–≥–≥–µ—Ä–∞
import inject # –î–æ–±–∞–≤–ª–µ–Ω–æ –¥–ª—è inject.autoparams

from game_server.Logic.InfrastructureLogic.arq_worker.arq_manager import ArqQueueService
from game_server.Logic.InfrastructureLogic.arq_worker.utils.task_batch_dispatcher import split_into_batches
from game_server.config.provider import config
from game_server.Logic.InfrastructureLogic.app_cache.services.task_queue.redis_batch_store import RedisBatchStore
from .base_command_handler import ICommandHandler


class AutoExploringHandler(ICommandHandler):
    """ –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –∫–æ–º–∞–Ω–¥—ã 'process_auto_exploring'. """

    # üî• –ò–ó–ú–ï–ù–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º inject.autoparams –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –≤–Ω–µ–¥—Ä–µ–Ω–∏—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
    @inject.autoparams('redis_batch_store', 'arq_service')
    def __init__(
        self,
        redis_batch_store: RedisBatchStore,
        arq_service: ArqQueueService,
        # logger: logging.Logger # –õ–æ–≥–≥–µ—Ä –±—É–¥–µ—Ç –ø–æ–ª—É—á–µ–Ω –∏–∑ –±–∞–∑–æ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞ —á–µ—Ä–µ–∑ inject.attr
    ):
        # super().__init__(dependencies) # üî• –£–î–ê–õ–ï–ù–û: –ë–æ–ª—å—à–µ –Ω–µ –ø–µ—Ä–µ–¥–∞–µ–º dependencies –≤ –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å

        self.redis_batch_store = redis_batch_store
        self.arq_service = arq_service

        self.logger.info("‚úÖ AutoExploringHandler (v2, RedisBatchStore) –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")

    async def execute(self, payload: Dict[str, Any]) -> None:
        character_ids = payload.get("character_ids", [])
        if not character_ids:
            self.logger.warning("AutoExploringHandler: –ø–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ ID –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É.")
            return

        self.logger.info(f"AutoExploringHandler: –ø–æ–ª—É—á–µ–Ω–æ {len(character_ids)} ID –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")

        category_name = "auto_exploring"

        batch_size = config.settings.runtime.BATCH_SIZES.get(category_name, config.settings.runtime.DEFAULT_BATCH_SIZE)
        arq_task_name = config.constants.coordinator.ARQ_COMMAND_TASK_NAMES.get(category_name)

        key_template = config.constants.coordinator.AUTO_EXPLORING_BATCH_KEY_TEMPLATE

        if not arq_task_name or not key_template:
            self.logger.error(f"–î–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–º—è ARQ-–∑–∞–¥–∞—á–∏ –∏–ª–∏ —à–∞–±–ª–æ–Ω –∫–ª—é—á–∞ Redis. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
            return

        instructions = [{"character_id": char_id, "task_type": category_name} for char_id in character_ids]

        successful_batches = 0
        failed_batches = 0
        for batch_instructions in split_into_batches(instructions, batch_size):
            try:
                redis_worker_batch_id = str(uuid.uuid4())

                batch_data_to_save = {
                    "specs": batch_instructions,
                    "target_count": len(batch_instructions),
                    "status": "pending"
                }

                success = await self.redis_batch_store.save_batch(
                    batch_id=redis_worker_batch_id,
                    key_template=key_template,
                    batch_data=batch_data_to_save,
                    ttl_seconds=config.settings.redis.BATCH_TASK_TTL_SECONDS
                )

                if success:
                    await self.arq_service.enqueue_job(
                        arq_task_name,
                        batch_id=redis_worker_batch_id
                    )
                    successful_batches += 1
                    self.logger.debug(f"–ó–∞–¥–∞—á–∞ '{arq_task_name}' —Å batch_id '{redis_worker_batch_id}' –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∞ –≤ –æ—á–µ—Ä–µ–¥—å ARQ. ({len(batch_instructions)} –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π)")
                else:
                    failed_batches += 1
                    self.logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –±–∞—Ç—á ID '{redis_worker_batch_id}' –≤ Redis. ARQ-–∑–∞–¥–∞—á–∞ –Ω–µ –±—É–¥–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞.")
            except Exception as e:
                failed_batches += 1
                self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –±–∞—Ç—á–∞ –¥–ª—è '{category_name}' (–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π: {len(batch_instructions)}): {e}", exc_info=True)

        if successful_batches > 0:
            self.logger.info(f"AutoExploringHandler: –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ. –ü–æ—Å—Ç–∞–≤–ª–µ–Ω–æ {successful_batches} –±–∞—Ç—á–µ–π –∑–∞–¥–∞—á '{arq_task_name}' –≤ –æ—á–µ—Ä–µ–¥—å. –û—à–∏–±–æ–∫: {failed_batches}.")
        elif failed_batches > 0:
            self.logger.error(f"AutoExploringHandler: –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ. –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç–∞–≤–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –±–∞—Ç—á–∞ '{arq_task_name}' –≤ –æ—á–µ—Ä–µ–¥—å. –û—à–∏–±–æ–∫: {failed_batches}.")
        else:
            self.logger.info("AutoExploringHandler: –ó–∞–¥–∞—á–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–µ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω—ã –∏–ª–∏ –±–∞—Ç—á–∏ –ø—É—Å—Ç—ã.")