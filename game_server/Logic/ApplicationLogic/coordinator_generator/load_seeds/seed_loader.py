# game_server/utils/load_seeds/seed_loader.py

import json
import os
import uuid
import yaml
from pathlib import Path
from typing import Dict, Any, Optional, Type
from sqlalchemy import UUID, inspect, select, delete
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.exc import IntegrityError
from sqlalchemy.dialects.postgresql import insert as pg_insert

from game_server.Logic.ApplicationLogic.coordinator_generator.load_seeds.yaml_readers import YamlReader
from game_server.database.models.models import Base
from game_server.services.logging.logging_setup import logger

from .seeds_config import SeedsConfig

class SeedLoader:
    def __init__(self, session: AsyncSession):
        self.session = session
        logger.info("‚úÖ SeedLoader –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    async def load_yaml_data(self, file_path: Path) -> Optional[Dict[str, Any]]:
        try:
            logger.debug(f"üìÇ –ó–∞–≥—Ä—É–∂–∞–µ–º YAML: {file_path}")
            with open(str(file_path), 'r', encoding='utf-8') as f:
                loaded_data = yaml.safe_load(f)
                logger.debug(f"üîç –ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –∏–∑ YAML '{file_path}': —Ç–∏–ø: {type(loaded_data)}, –∫–ª—é—á–∏: {loaded_data.keys() if isinstance(loaded_data, dict) else 'N/A'}")
                return loaded_data
        except FileNotFoundError:
            logger.warning(f"‚ö†Ô∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}. –ü—Ä–æ–ø—É—Å–∫ –∑–∞–≥—Ä—É–∑–∫–∏.")
            return None
        except yaml.YAMLError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ YAML –≤ —Ñ–∞–π–ª–µ {file_path}: {str(e)}")
            return None
        except Exception as e:
            logger.error(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {file_path}: {str(e)}", exc_info=True)
            return None

    async def process_seed_file(self, file_path: Path, model: Type[Base]) -> tuple[int, int]:
        logger.debug(f"üìú –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º seed-—Ñ–∞–π–ª: {file_path} ({model.__name__})")

        pk_column_names = [col.name for col in inspect(model).primary_key]
        logger.debug(f"üîç –ü–µ—Ä–≤–∏—á–Ω—ã–µ –∫–ª—é—á–∏ –¥–ª—è –º–æ–¥–µ–ª–∏ {model.__name__}: {pk_column_names}")

        if not pk_column_names:
            logger.error(f"‚ùå –ú–æ–¥–µ–ª—å {model.__name__} –Ω–µ –∏–º–µ–µ—Ç –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –∫–ª—é—á–∞. –ü—Ä–æ–ø—É—Å–∫ —Ñ–∞–π–ª–∞.")
            return 0, 0
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–º—è PK –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ YamlReader, –µ—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö - —Å–ª–æ–≤–∞—Ä—å
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º SeedsConfig.get_pk_column –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è PK
        pk_for_yaml_reader = SeedsConfig.get_pk_column(model) 
        if not pk_for_yaml_reader:
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–µ—Ä–≤–∏—á–Ω—ã–π –∫–ª—é—á –¥–ª—è –º–æ–¥–µ–ª–∏ '{model.__name__}'. –ü—Ä–æ–ø—É—Å–∫ —Ñ–∞–π–ª–∞.")
            return 0, 0

        # === –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º YamlReader –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è items_to_process ===
        items_to_process = await YamlReader.get_items_from_yaml(file_path, pk_for_yaml_reader)
        # === –ö–û–ù–ï–¶ –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø ===

        logger.debug(f"üìä –í—Å–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ —Ñ–∞–π–ª–µ: {len(items_to_process)}")

        if not items_to_process:
            logger.warning(f"‚ö†Ô∏è –§–∞–π–ª {file_path} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏. –£–¥–∞–ª—è–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ –¥–ª—è –º–æ–¥–µ–ª–∏ {model.__name__}...")
            deleted_count = await self._clear_model_data(model)
            await self.session.commit()
            logger.info(f"‚úÖ –£–¥–∞–ª–µ–Ω–æ {deleted_count} –∑–∞–ø–∏—Å–µ–π –∏–∑ —Ç–∞–±–ª–∏—Ü—ã {model.__tablename__}.")

        # –£—Å–ª–æ–≤–∏–µ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ —Ç–∞–±–ª–∏—Ü—ã, –µ—Å–ª–∏ items_to_process –ø—É—Å—Ç–æ
        if not items_to_process: # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º items_to_process, –∞ –Ω–µ data['data']
            logger.warning(f"‚ö†Ô∏è –§–∞–π–ª {file_path} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏. –£–¥–∞–ª—è–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ –¥–ª—è –º–æ–¥–µ–ª–∏ {model.__name__}...")
            deleted_count = await self._clear_model_data(model)
            await self.session.commit()
            logger.info(f"‚úÖ –£–¥–∞–ª–µ–Ω–æ {deleted_count} –∑–∞–ø–∏—Å–µ–π –∏–∑ —Ç–∞–±–ª–∏—Ü—ã {model.__tablename__}.")
            return 0, 0

        inserted_count, updated_count = 0, 0

        batch_size = SeedsConfig.BATCH_SIZE
        logger.debug(f"üìä –í—Å–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ —Ñ–∞–π–ª–µ: {len(items_to_process)}")

        for i in range(0, len(items_to_process), batch_size):
            batch = items_to_process[i:i + batch_size]
            logger.debug(f"üì¶ –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ {i // batch_size + 1}/{len(items_to_process) // batch_size + (1 if len(items_to_process) % batch_size > 0 else 0)} (—Ä–∞–∑–º–µ—Ä: {len(batch)})")
            
            batch_values = []
            for item_data in batch:
                missing_pk_keys = [col for col in pk_column_names if col not in item_data]
                if missing_pk_keys:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞: –í —ç–ª–µ–º–µ–Ω—Ç–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–ª—é—á–∏ –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –∫–ª—é—á–∞ {missing_pk_keys} –¥–ª—è {model.__name__}! –≠–ª–µ–º–µ–Ω—Ç: {item_data}. –ü—Ä–æ–ø—É—Å–∫ —ç–ª–µ–º–µ–Ω—Ç–∞.")
                    continue
                
                for col in inspect(model).columns:
                    if isinstance(col.type, UUID) and col.name in item_data and isinstance(item_data[col.name], str):
                        try:
                            item_data[col.name] = uuid.UUID(item_data[col.name])
                            logger.debug(f"    üîÑ UUID –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω –¥–ª—è {col.name}: {item_data[col.name]}")
                        except ValueError:
                            logger.error(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π UUID –¥–ª—è {col.name} –≤ {model.__name__}: {item_data[col.name]}. –ü—Ä–æ–ø—É—Å–∫ —ç–ª–µ–º–µ–Ω—Ç–∞.")
                            continue
                batch_values.append(item_data)
            
            logger.debug(f"  üìù –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ batch_values –¥–ª—è UPSERT (—ç–ª–µ–º–µ–Ω—Ç–æ–≤: {len(batch_values)})")

            # üî•üî•üî• –ù–û–í–´–ô –õ–û–ì –î–õ–Ø –û–¢–õ–ê–î–ö–ò JSONB üî•üî•üî•
            # –ü–æ–ø—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–µ—á–∞—Ç–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ 'items' –¥–ª—è StarterInventory
            if model.__name__ == 'CharacterStarterInventory': # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ —Ç–æ—á–Ω–æ–µ –∏–º—è –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏
                for item_val in batch_values:
                    if 'items' in item_val:
                        logger.critical(f"DEBUG_JSONB: 'items' field type is {type(item_val['items'])}, value: {item_val['items']}")
                        # –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –æ—à–∏–±–∫—É –∑–¥–µ—Å—å
                        try:
                            json.dumps(item_val['items'])
                            logger.critical(f"DEBUG_JSONB: 'items' field IS JSON serializable.")
                        except Exception as json_e:
                            logger.critical(f"DEBUG_JSONB: 'items' field IS NOT JSON serializable: {json_e}", exc_info=True)
            # üî•üî•üî• –ö–û–ù–ï–¶ –ù–û–í–û–ì–û –õ–û–ì–ê üî•üî•üî•

            if not batch_values:
                logger.warning(f"  ‚ö†Ô∏è –ë–∞—Ç—á {i // batch_size + 1} –ø—É—Å—Ç –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏/–æ–±—Ä–∞–±–æ—Ç–∫–∏. –ü—Ä–æ–ø—É—Å–∫ UPSERT.")
                continue

            try:
                insert_stmt = pg_insert(model).values(batch_values)

                update_cols = {
                    col.name: getattr(insert_stmt.excluded, col.name)
                    for col in model.__table__.columns
                    if col.name not in pk_column_names
                }
                
                if not update_cols:
                    upsert_stmt = insert_stmt.on_conflict_do_nothing(index_elements=pk_column_names)
                    logger.debug(f"  ‚ö°Ô∏è –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è UPSERT (DO NOTHING) –¥–ª—è {model.__name__} –ø–æ PK: {pk_column_names}")
                else:
                    upsert_stmt = insert_stmt.on_conflict_do_update(
                        index_elements=pk_column_names,
                        set_=update_cols
                    )
                    logger.debug(f"  ‚ö°Ô∏è –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è UPSERT (DO UPDATE) –¥–ª—è {model.__name__} –ø–æ PK: {pk_column_names}, –æ–±–Ω–æ–≤–ª—è–µ–º—ã–µ –ø–æ–ª—è: {list(update_cols.keys())}")
                
                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –£–¥–∞–ª—è–µ–º problematic_returning_clause.
                # –ü—Ä–æ—Å—Ç–æ –≤—ã–ø–æ–ª–Ω—è–µ–º UPSERT-–∑–∞–ø—Ä–æ—Å –±–µ–∑ RETURNING –¥–ª—è –æ–±—Ö–æ–¥–∞ TypeError.
                await self.session.execute(upsert_stmt)
                
                # –ü–æ—Å–∫–æ–ª—å–∫—É –º—ã –Ω–µ –ø–æ–ª—É—á–∞–µ–º returned_ids, –º—ã –Ω–µ –º–æ–∂–µ–º —Ç–æ—á–Ω–æ –ø–æ—Å—á–∏—Ç–∞—Ç—å updated_count –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞.
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º updated_count –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ –±–∞—Ç—á–µ, –µ—Å–ª–∏ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –≤—Å–µ –æ–Ω–∏ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è.
                updated_count += len(batch_values)
                logger.debug(f"  ‚úÖ UPSERT –≤—ã–ø–æ–ª–Ω–µ–Ω –¥–ª—è {model.__name__}. –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ –∑–∞—Ç—Ä–æ–Ω—É—Ç–æ: {len(batch_values)} —Å—Ç—Ä–æ–∫.")

            except IntegrityError as e:
                await self.session.rollback()
                logger.error(f"‚ùå IntegrityError –ø—Ä–∏ UPSERT –¥–ª—è {model.__name__}, –±–∞—Ç—á (–Ω–∞—á–∞–ª–æ): {batch[0] if batch else 'N/A'}: {e}", exc_info=True)
            except Exception as e:
                await self.session.rollback()
                logger.error(f"‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ UPSERT –¥–ª—è {model.__name__}, –±–∞—Ç—á (–Ω–∞—á–∞–ª–æ): {batch[0] if batch else 'N/A'}: {e}", exc_info=True)
            
            await self.session.commit()
            logger.debug(f"üíæ –ö–æ–º–º–∏—Ç –¥–∞–Ω–Ω—ã—Ö (–±–∞—Ç—á: {len(batch_values)} –∑–∞–ø–∏—Å–µ–π). –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {updated_count}")

        logger.debug(f"‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ {os.path.basename(file_path)}: {inserted_count} –≤—Å—Ç–∞–≤–ª–µ–Ω–æ, {updated_count} –æ–±–Ω–æ–≤–ª–µ–Ω–æ")
        return inserted_count, updated_count

    async def _clear_model_data(self, model: Type[Base]) -> int:
        """–ù–û–í–ê–Ø –§–£–ù–ö–¶–ò–Ø: –£–¥–∞–ª—è–µ—Ç –≤—Å–µ –∑–∞–ø–∏—Å–∏ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏."""
        try:
            result = await self.session.execute(delete(model))
            logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω—ã –≤—Å–µ –∑–∞–ø–∏—Å–∏ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã {model.__tablename__}.")
            return result.rowcount
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ —Ç–∞–±–ª–∏—Ü—ã {model.__tablename__}: {e}", exc_info=True)
            await self.session.rollback() 
            return 0