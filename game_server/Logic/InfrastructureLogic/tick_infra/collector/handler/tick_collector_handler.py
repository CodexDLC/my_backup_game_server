
# game_server\Logic\InfrastructureLogic\tick_infra\collector\handler\tick_collector_handler.py


import json
from datetime import timedelta
import time
from sqlalchemy import func
from game_server.Logic.InfrastructureLogic.tick_infra.tick_utils.task_utils import get_tick_status, set_tick_status
from game_server.Logic.InfrastructureLogic.tick_infra.tick_utils.tick_logger import logger
from game_server.Logic.DataAccessLogic.db_in import AsyncDatabase

# –ò–º–ø–æ—Ä—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ñ–æ–Ω–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—á–µ—Ä–µ–¥–∏ –∏–∑ –æ—á–µ—Ä–µ–¥–Ω–æ–≥–æ –º–æ–¥—É–ª—è:


async def get_ready_characters(db: AsyncDatabase):
    """–í—ã–±–∏—Ä–∞–µ—Ç –≥–æ—Ç–æ–≤—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –ø–æ `next_tick_at` –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –ø–æ–ª–µ `active_category` –≤ `task_type`."""
    logger.debug("üîé –ó–∞–ø—É—Å–∫ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π —á–µ—Ä–µ–∑ –ø—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π...")

    query = "SELECT * FROM auto_sessions WHERE next_tick_at <= NOW()"
    try:
        logger.debug(f"üîç –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å: {query}")
        rows = await db.get_data(query)
        logger.debug(f"üßê –ü–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {rows}")

        characters = []
        for row in rows:
            character = dict(row)
            if 'active_category' in character:
                character['task_type'] = character.pop('active_category')
            characters.append(character)

        logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(characters)} –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π.")  # üîπ –ò—Ç–æ–≥–æ–≤—ã–π –ª–æ–≥ –≤ `INFO`
        return characters
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}", exc_info=True)
        return []


async def send_to_redis(active_sessions, redis_client, tick_id):
    """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π —Å –ø—Ä–∏–≤—è–∑–∫–æ–π –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É —Ç–∏–∫—É –≤ –∫–æ–º–ø–∞–∫—Ç–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ."""
    try:
        logger.debug(f"üì§ –ì–æ—Ç–æ–≤–∏–º—Å—è –∑–∞–ø–∏—Å–∞—Ç—å {len(active_sessions)} –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –≤ Redis...")

        for session in active_sessions:
            short_code = f"{session['task_type'][0].upper()}:{session['character_id']}:{tick_id}"  # E, C, T
            await redis_client.rpush("tick_processing_queue", short_code)

            # ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º `set_tick_status()`
            await set_tick_status(redis_client, session['character_id'], tick_id, "I")

            logger.debug(f"üü¢ –ó–∞–ø–∏—Å–∞–Ω –ø–µ—Ä—Å–æ–Ω–∞–∂ {session['character_id']} ‚Üí –¢–∏–∫: {tick_id}, –¢–∏–ø: {session['task_type']}.")

        logger.info(f"‚úÖ –ó–∞–ø–∏—Å—å –∑–∞–≤–µ—Ä—à–µ–Ω–∞! {len(active_sessions)} –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ Redis.")

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –≤ Redis: {e}", exc_info=True)

       

async def update_tick_info(character_id: int, db: AsyncDatabase):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç `last_tick_at` –∏ `next_tick_at` —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ `db`."""
    logger.debug(f"üîÑ –ù–∞—á–∏–Ω–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ {character_id}...")  # üîπ `DEBUG` –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π

    query_select = "SELECT last_tick_at, next_tick_at FROM auto_sessions WHERE character_id = $1"
    query_update = "UPDATE auto_sessions SET last_tick_at = $1, next_tick_at = $2 WHERE character_id = $3"

    updated_count = 0  # ‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—á–µ—Ç—á–∏–∫

    try:
        char = await db.get_data(query_select, character_id)  # ‚úÖ –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ `db`

        if char:
            char = char[0]  # ‚úÖ `get_data()` –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫, –±–µ—Ä—ë–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç
            logger.debug(f"üîç –î–∞–Ω–Ω—ã–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ {character_id}: last_tick_at={char['last_tick_at']}, next_tick_at={char['next_tick_at']}")

            # üîÑ –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç–∏–∫–∞
            new_last_tick = char['next_tick_at']
            new_next_tick = new_last_tick + timedelta(minutes=1)

            # ‚úÖ –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –≤ –ë–î
            await db.save_data(query_update, new_last_tick, new_next_tick, character_id)

            updated_count += 1  # ‚úÖ –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –ø—Ä–∏ —É—Å–ø–µ—à–Ω–æ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏
            
            logger.debug(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ last_tick_at={new_last_tick}, next_tick_at={new_next_tick} –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ {character_id}.")
        else:
            logger.warning(f"‚ö† –ü–µ—Ä—Å–æ–Ω–∞–∂ {character_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ.")  # üîπ `WARNING`, –µ—Å–ª–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ {character_id}: {e}", exc_info=True)  # üîπ `ERROR` –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
    
    # ‚úÖ –ò—Ç–æ–≥–æ–≤—ã–π `INFO`-–ª–æ–≥ –≤ –∫–æ–Ω—Ü–µ
    logger.info(f"‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–∏–∫–æ–≤. –£—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–æ {updated_count} –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π.")


async def fetch_and_process_tasks(redis_client):
    """–ü–æ–ª—É—á–∞–µ—Ç –∑–∞–¥–∞—á–∏ –∏–∑ `tick_processing_queue`, –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞—Ç—É—Å –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ—Ç."""
    logger.debug("üîÑ –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–¥–∞—á –∏–∑ `tick_processing_queue`...")  # üîπ `DEBUG` –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º

    raw_tasks = await redis_client.lrange("tick_processing_queue", 0, -1)

    if not raw_tasks:
        logger.info("‚úÖ –û—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞, –Ω–µ—Ç –∑–∞–¥–∞—á –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")  # üîπ `INFO` —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        return []

    parsed_tasks = []
    for task in raw_tasks:
        task = task.decode("utf-8") if isinstance(task, bytes) else task
        parts = task.split(":")
        
        if len(parts) != 3:
            logger.warning(f"‚ö† –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∑–∞–¥–∞—á–∏: {task}")  # üîπ `WARNING`, –µ—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç –Ω–µ–≤–µ—Ä–Ω—ã–π
            continue

        task_type, character_id, tick_id = parts
        flag = await get_tick_status(redis_client, character_id, tick_id)

        if flag != "I":
            logger.debug(f"üîï –ü—Ä–æ–ø—É—â–µ–Ω–∞ –∑–∞–¥–∞—á–∞ `{task}` (—Å—Ç–∞—Ç—É—Å: {flag})")  # üîπ `DEBUG`, –µ—Å–ª–∏ —Å—Ç–∞—Ç—É—Å –Ω–µ `I`
            continue

        parsed_tasks.append({
            "task_type": task_type,
            "character_id": character_id,
            "tick_id": tick_id
        })
    
    logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(parsed_tasks)} –∑–∞–¥–∞—á –∏–∑ `tick_processing_queue`.")  # üîπ `INFO` –∏—Ç–æ–≥
    return parsed_tasks


async def categorize_tasks(parsed_tasks, redis_client):
    """–ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç –∑–∞–¥–∞—á–∏ –ø–æ `task_type`, —Å–æ–∑–¥–∞—ë—Ç `batch_id`, —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ Redis."""
    logger.debug("üîÑ –ó–∞–ø—É—Å–∫ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –∑–∞–¥–∞—á –ø–æ `task_type`...")

    task_groups = {}
    server_start_time = int(await redis_client.get("server_start_time") or time.time())
    batch_counter = int(await redis_client.get("batch_counter") or 1)

    for task in parsed_tasks:
        task_type = task["task_type"]
        batch_id = f"{task_type}_{server_start_time}_{batch_counter}"

        if len(task_groups.get(batch_id, [])) >= 100:
            batch_counter += 1
            batch_id = f"{task_type}_{server_start_time}_{batch_counter}"

        task_groups.setdefault(batch_id, []).append(task)
        logger.debug(f"üì¶ –î–æ–±–∞–≤–ª–µ–Ω–∞ –∑–∞–¥–∞—á–∞ `{task}` –≤ batch `{batch_id}`.")

    for batch_id, tasks in task_groups.items():
        await redis_client.hset("processed_batches", batch_id, json.dumps(tasks))
        await redis_client.hset("batch_status", batch_id, "initiation")
        logger.debug(f"üóÉÔ∏è –°–æ—Ö—Ä–∞–Ω–µ–Ω batch `{batch_id}` —Å {len(tasks)} –∑–∞–¥–∞—á–∞–º–∏.")

    await redis_client.set("batch_counter", batch_counter)
    logger.info(f"‚úÖ –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –°–æ–∑–¥–∞–Ω–æ {len(task_groups)} batch.")
    
    return task_groups


async def cleanup_tick_processing_queue(redis_client):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∞—Ç –ª–∏ –≤—Å–µ `processed_batches` –∑–∞–¥–∞—á–∏ –∏–∑ `tick_processing_queue`. –ï—Å–ª–∏ –¥–∞ ‚Äî –æ–±–Ω–æ–≤–ª—è–µ—Ç –∏—Ö —Å—Ç–∞—Ç—É—Å –Ω–∞ `done` –∏ –æ—á–∏—â–∞–µ—Ç `tick_processing_queue`."""
    
    logger.debug("üîÑ –ó–∞–ø—É—Å–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è `tick_processing_queue` –∏ `processed_batches`...")  

    raw_tasks = await redis_client.lrange("tick_processing_queue", 0, -1)
    if not raw_tasks:
        logger.info("‚úÖ `tick_processing_queue` —É–∂–µ –ø—É—Å—Ç, –æ—á–∏—Å—Ç–∫–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")  
        return

    task_set = set(raw_tasks)
    logger.debug(f"üì¶ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(task_set)} –∑–∞–¥–∞—á –∏–∑ `tick_processing_queue`.")

    processed_batches_raw = await redis_client.hgetall("processed_batches")
    
    if not processed_batches_raw:
        logger.warning("‚ö† `processed_batches` –ø—É—Å—Ç, —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ!")  
        return
    
    batch_task_set = set()
    for batch_id, tasks_json in processed_batches_raw.items():
        tasks = json.loads(tasks_json)
        for task in tasks:
            batch_task_set.add(f"{task['task_type']}:{task['character_id']}:{task['tick_id']}")  

    logger.debug(f"üóÇÔ∏è –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(batch_task_set)} –∑–∞–¥–∞—á –∏–∑ `processed_batches` –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.")

    if task_set.issubset(batch_task_set):
        logger.info("‚úÖ –í—Å–µ –∑–∞–¥–∞—á–∏ –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω—ã –≤ `processed_batches`, –æ–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å `tick_status` ‚Üí `done`...")
        
        for task in task_set:
            task_parts = task.split(":")
            if len(task_parts) >= 3:
                tick_key = f"tick_status_{task_parts[1]}_{task_parts[2]}"  
                await redis_client.hset("tick_status", tick_key, "done")
                logger.debug(f"üü¢ –û–±–Ω–æ–≤–ª—ë–Ω —Å—Ç–∞—Ç—É—Å `{tick_key}` ‚Üí `done`")

        await redis_client.delete("tick_processing_queue")  
        logger.info("üèÅ –û—á–∏—Å—Ç–∫–∞ `tick_processing_queue` –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    else:
        remaining_tasks = task_set - batch_task_set
        logger.debug(f"üîç –û—Å—Ç–∞–ª–æ—Å—å {len(remaining_tasks)} –∑–∞–¥–∞—á, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ `processed_batches`.")
        logger.info("üîÑ –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –∑–∞–¥–∞—á–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ `processed_batches`, –æ—á–∏—Å—Ç–∫–∞ `tick_processing_queue` –Ω–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è.")

