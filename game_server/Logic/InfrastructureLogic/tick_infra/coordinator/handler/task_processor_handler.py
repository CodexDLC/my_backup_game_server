
import asyncio
import sys
from game_server.Logic.InfrastructureLogic.tick_infra.tick_utils.tick_logger import logger  # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ª–æ–≥–≥–µ—Ä



WORKER_DISTRIBUTION = {
    "exploration": 0.5,  # 50%
    "crafting": 0.2,  # 20%
    "trade": 0.2,  # 20%
    "other": 0.1,  # 10%
}

queue_names = [
"tick_exploration",
"tick_crafting", 
"tick_trade", 
"tick_general"
]


MAX_WORKERS = 10  # üîπ –õ–µ–≥–∫–æ –º–µ–Ω—è–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Ä–∫–µ—Ä–æ–≤


async def get_initiation_batches(redis_client):
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ batch_id —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º 'initiation' –∏–∑ Redis.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∏–ª–∏ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫, –µ—Å–ª–∏ –Ω–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –∑–∞–ø–∏—Å–µ–π.
    –õ–æ–≥–∏—Ä—É–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —ç—Ç–∞–ø—ã —Ä–∞–±–æ—Ç—ã –∏ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã.
    """
    try:
        # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞—á–∞–ª–æ –æ–ø–µ—Ä–∞—Ü–∏–∏
        logger.debug("–ù–∞—á–∞–ª–æ –ø–æ–ª—É—á–µ–Ω–∏—è batch_id —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º 'initiation'")
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ —Å—Ç–∞—Ç—É—Å–æ–≤
        batch_status_all = await redis_client.hgetall("batch_status")
        logger.debug(f"–ü–æ–ª—É—á–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π –∏–∑ Redis: {len(batch_status_all)}")
        
        if not batch_status_all:
            logger.info("–í Redis –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –¥–∞–Ω–Ω—ã–µ –≤ hash 'batch_status'")
            return []
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ initiation —Å—Ç–∞—Ç—É—Å—ã
        initiation_batches = [
            batch_id 
            for batch_id, status in batch_status_all.items() 
            if status == "initiation"
        ]
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if initiation_batches:
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ batch_id –≤ —Å—Ç–∞—Ç—É—Å–µ 'initiation': {len(initiation_batches)}")
        else:
            logger.info("–ó–∞–ø–∏—Å–∏ —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º 'initiation' –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")
        
        return initiation_batches
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ batch_id: {str(e)}", exc_info=True)
        raise  # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–∞–ª—å—à–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—ã–∑—ã–≤–∞—é—â–µ–π —Å—Ç–æ—Ä–æ–Ω–æ–π

def calculate_free_workers():
    free_workers = {
        task_type: max(1, int(MAX_WORKERS * ratio))
        for task_type, ratio in WORKER_DISTRIBUTION.items()
    }
    return free_workers


async def get_available_batches(initiation_batches, free_workers, redis_client):
    """–†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç batch_id –ø–æ –≤–æ—Ä–∫–µ—Ä–∞–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ Redis."""
    task_type_map = {"E": "exploration", "C": "crafting", "T": "trade", "O": "other"}
    max_to_process = 10
    initiation_batches_process = initiation_batches[:max_to_process]
    available_workers = []
    free_workers_copy = free_workers.copy()

    # 1. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á –ø–æ –≤–æ—Ä–∫–µ—Ä–∞–º (–ø—Ä–µ–∂–Ω—è—è –ª–æ–≥–∏–∫–∞)
    leftovers = []
    for batch_id in initiation_batches_process:
        prefix = batch_id.split("_")[0]
        task_type = task_type_map.get(prefix)
        if task_type and free_workers_copy.get(task_type, 0) > 0:
            available_workers.append({
                "batch_id": batch_id,
                "task_type": task_type,
                "original_task_type": task_type
            })
            free_workers_copy[task_type] -= 1
        else:
            leftovers.append(batch_id)

    # 2. –ü–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Å—Ç–∞—Ç–∫–æ–≤ (–ø—Ä–µ–∂–Ω—è—è –ª–æ–≥–∏–∫–∞)
    if leftovers:
        total_free = sum(free_workers_copy.values())
        if total_free > 0:
            for batch_id in leftovers:
                prefix = batch_id.split("_")[0]
                task_type = task_type_map.get(prefix)
                if not task_type:
                    continue
                for wt, count in free_workers_copy.items():
                    if count > 0:
                        available_workers.append({
                            "batch_id": batch_id,
                            "task_type": task_type,
                            "original_task_type": wt
                        })
                        free_workers_copy[wt] -= 1
                        break

    # 3. üî• –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Redis (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ!)
    if available_workers:  # —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ
        import uuid
        archive_id = str(uuid.uuid4())  # —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–ª—è –∞—Ä—Ö–∏–≤–∞
        await redis_client.hset(
            "available_workers_archive",
            archive_id,
            str(available_workers)  # –∏–ª–∏ json.dumps(available_workers)
        )
        logger.info(f"üóÑ –°–ø–∏—Å–æ–∫ available_workers —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ –∞—Ä—Ö–∏–≤ –ø–æ–¥ –∫–ª—é—á–æ–º: {archive_id}")
    else:
        logger.info("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏ (available_workers –ø—É—Å—Ç)")

    return available_workers





async def run_worker(batch_id, task_type):
    try:
        process = await asyncio.create_subprocess_exec(
            sys.executable, 'game_server/Logic/InfrastructureLogic/tick_infra/handler/tick_handler.py',
            batch_id, task_type,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        try:
            stdout, stderr = await asyncio.wait_for(process.communicate(), timeout=10)
        except asyncio.TimeoutError:
            process.kill()
            await process.wait()
            logger.warning(f"‚ö†Ô∏è –¢–∞–π–º–∞—É—Ç —É –≤–æ—Ä–∫–µ—Ä–∞ batch_id={batch_id}")
            return

        if process.returncode != 0:
            logger.error(f"‚ùå –í–æ—Ä–∫–µ—Ä batch_id={batch_id} –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π: {stderr.decode()}")
        else:
            logger.info(f"‚úÖ –í–æ—Ä–∫–µ—Ä batch_id={batch_id} –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É.\nstdout: {stdout.decode()}")

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –≤–æ—Ä–∫–µ—Ä–∞ batch_id={batch_id}: {e}", exc_info=True)



async def process_available_batches(redis_client, available_workers):
    if not available_workers:
        logger.info("‚úÖ –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∑–∞–¥–∞—á, –∑–∞–≤–µ—Ä—à–∞–µ–º `process_available_batches`.")
        return []

    completed_batches = []
    i = 0
    while i < len(available_workers):
        try:
            batch_info = available_workers[i]
            batch_id = batch_info["batch_id"]
            task_type = batch_info["task_type"]

            logger.debug(f"üîç [DEBUG] –ü—Ä–æ–≤–µ—Ä–∫–∞ `batch_status` –¥–ª—è `batch_id={batch_id}`...")
            current_status = await redis_client.hget("batch_status", batch_id)

            if current_status == "done":
                logger.debug(f"‚úÖ [DEBUG] batch_id={batch_id} —É–∂–µ –∑–∞–≤–µ—Ä—à—ë–Ω, —É–¥–∞–ª—è–µ–º –∏–∑ —Å–ø–∏—Å–∫–∞.")
                available_workers.pop(i)
                completed_batches.append(batch_id)
                continue

            logger.info(f"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É `batch_id={batch_id}` –≤ —Å—É–±–ø—Ä–æ—Ü–µ—Å—Å–µ...")

            process = await asyncio.create_subprocess_exec(
                'python', 'game_server/Logic/InfrastructureLogic/tick_infra/handler/tick_handler.py', batch_id, task_type,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )

            try:
                stdout, stderr = await asyncio.wait_for(process.communicate(), timeout=10)
            except asyncio.TimeoutError:
                logger.warning(f"‚è∞ –í—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç—á—ë—Ç–∞ –æ—Ç batch_id={batch_id} –∏—Å—Ç–µ–∫–ª–æ, –æ—Å—Ç–∞–≤–ª—è–µ–º –∑–∞–¥–∞—á—É –≤ —Å–ø–∏—Å–∫–µ.")
                i += 1
                continue

            logger.info(f"üõ† –í–æ—Ä–∫–µ—Ä `{batch_id}` –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É.\nstdout: {stdout.decode()}\nstderr: {stderr.decode()}")
            completed_batches.append(batch_id)
            available_workers.pop(i)

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ `process_available_batches`: {e}", exc_info=True)
            i += 1
            continue

    return completed_batches



   
async def process_tasks(redis_client):
    initiation_batches = await get_initiation_batches(redis_client)

    while initiation_batches:
        free_workers = calculate_free_workers()

        available_workers = await get_available_batches(initiation_batches, free_workers, redis_client)
        if not available_workers:
            break

        completed_batches = await process_available_batches(redis_client, available_workers)

        for batch_id in completed_batches:
            await redis_client.hset("batch_status", batch_id, "done")

        initiation_batches = [b for b in initiation_batches if b not in completed_batches]

        await asyncio.sleep(2)



