
from game_server.Logic.InfrastructureLogic.tick_infra.tick_utils.tick_logger import logger
import json



async def extract_active_handlers(redis_client):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç `active_handlers`, –ø–∞—Ä—Å–∏—Ç JSON –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 3 —Å–ø–∏—Å–∫–∞: batch_id, handler_name, status."""
    active_handlers_raw = await redis_client.hgetall("active_handlers")

    if not active_handlers_raw:
        logger.info("‚úÖ `active_handlers` –ø—É—Å—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç—Ä–∏ –ø—É—Å—Ç—ã—Ö —Å–ø–∏—Å–∫–∞.")
        return [], [], []

    batch_ids = []
    handler_names = []
    statuses = []

    for batch_id, json_data in active_handlers_raw.items():
        try:
            fixed_json = json_data.replace("'", "\"")  # üî• –ó–∞–º–µ–Ω—è–µ–º –∫–∞–≤—ã—á–∫–∏ –ø–µ—Ä–µ–¥ –ø–∞—Ä—Å–∏–Ω–≥–æ–º
            parsed_data = json.loads(fixed_json)  
            
            batch_ids.append(parsed_data.get("batch_id"))
            handler_names.append(parsed_data.get("handler_name"))
            statuses.append(parsed_data.get("status"))
        except json.JSONDecodeError:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –¥–ª—è batch_id={batch_id}, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º!")



    logger.debug(f"üîç –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(batch_ids)} –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤.")
    return batch_ids, handler_names, statuses




async def process_batch_report(redis_client):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç `batch_id` + `status` –≤ —Ñ–∞–π–ª, –∞ `failed_tasks` —Å–æ–±–∏—Ä–∞–µ—Ç –≤ —Å–ø–∏—Å–æ–∫."""
    batch_reports = await redis_client.hgetall("finish_handlers_tick")

    if not batch_reports:
        logger.info("‚úÖ `finish_handlers_tick` –ø—É—Å—Ç, –Ω–µ—á–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å.")
        return [], []

    failed_tasks_list = []
    batch_status_list = []

    for batch_id, report_json in batch_reports.items():
        try:
            report_data = json.loads(report_json)

            # ‚úÖ –î–æ–±–∞–≤–ª—è–µ–º `batch_id` + `status` –≤ —Å–ø–∏—Å–æ–∫
            batch_status_list.append({
                "batch_id": report_data.get("batch_id"),
                "status": report_data.get("status")
            })

            # ‚úÖ –°–æ–±–∏—Ä–∞–µ–º `failed_tasks` –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫
            failed_tasks = report_data.get("failed_tasks")
            if failed_tasks and failed_tasks != "[]":  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –æ—à–∏–±–∫–∏
                failed_tasks_list.extend(json.loads(failed_tasks))

        except json.JSONDecodeError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –¥–ª—è batch_id={batch_id}: {e}")

    # ‚úÖ –ó–∞–ø–∏—Å—ã–≤–∞–µ–º `batch_status_list` –≤ —Ñ–∞–π–ª
    with open("batch_status_report.json", "w", encoding="utf-8") as file:
        json.dump(batch_status_list, file, ensure_ascii=False, indent=4)

    logger.info("üèÅ `batch_status_report.json` —Å–æ–∑–¥–∞–Ω, `failed_tasks` —Å–æ–±—Ä–∞–Ω—ã!")
    
    return batch_status_list, failed_tasks_list


async def cleanup_successful_handlers(redis_client, batch_status_list, batch_ids):
    """–£–¥–∞–ª—è–µ—Ç `batch_id` –∏–∑ `active_handlers`, –µ—Å–ª–∏ –µ–≥–æ —Å—Ç–∞—Ç—É—Å –≤ `batch_status_list` == `"success"`."""
    if not batch_status_list or not batch_ids:
        logger.info("‚úÖ –°–ø–∏—Å–∫–∏ `batch_status_list` –∏ `batch_ids` –ø—É—Å—Ç—ã, –æ—á–∏—Å—Ç–∫–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")
        return
    
    logger.info("üîç –ó–∞–ø—É—Å–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è `batch_status_list` –∏ `batch_ids`...")

    active_handlers = await redis_client.hgetall("active_handlers")
    
    if not active_handlers:
        logger.info("‚úÖ `active_handlers` –ø—É—Å—Ç, –Ω–µ—á–µ–≥–æ —É–¥–∞–ª—è—Ç—å.")
        return

    for batch_entry in batch_status_list:
        batch_id = batch_entry.get("batch_id")
        status = batch_entry.get("status")

        if batch_id in batch_ids and status == "success":
            await redis_client.hdel("active_handlers", batch_id)
            logger.debug(f"üóë –£–¥–∞–ª—ë–Ω `batch_id={batch_id}` –∏–∑ `active_handlers`")

    logger.info("üèÅ –û—á–∏—Å—Ç–∫–∞ `active_handlers` –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")



async def cleanup_available_workers(redis_client, batch_status_list, failed_tasks_list, active_handlers):
    """–£–¥–∞–ª—è–µ—Ç `batch_id` –∏–∑ `available_workers_archive`, –µ—Å–ª–∏ –µ–≥–æ —Å—Ç–∞—Ç—É—Å `success`, –æ–Ω –Ω–µ–∞–∫—Ç–∏–≤–µ–Ω –∏–ª–∏ –∏–º–µ–µ—Ç –æ—à–∏–±–∫–∏."""

    available_workers = await redis_client.hgetall("available_workers_archive")

    if not available_workers:
        logger.info("‚úÖ `available_workers_archive` –ø—É—Å—Ç, –Ω–µ—á–µ–≥–æ —É–¥–∞–ª—è—Ç—å.")
        return

    batch_ids_to_remove = set()

    for batch_id, worker_data in available_workers.items():
        try:
            # üîé –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å–ª–∏ `worker_data` ‚Äî —Å—Ç—Ä–æ–∫–∞, –∑–∞–º–µ–Ω—è–µ–º –∫–∞–≤—ã—á–∫–∏ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ JSON
            if isinstance(worker_data, str):
                worker_data = worker_data.replace("'", '"')  # ‚úÖ –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–≤—ã—á–∫–∏
            
            worker_info = json.loads(worker_data)  # ‚úÖ –ü–∞—Ä—Å–∏–º JSON

            # ‚úÖ –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ª–æ–≤–∏—è —É–¥–∞–ª–µ–Ω–∏—è
            if any(entry["batch_id"] == batch_id and entry["status"] == "success" for entry in batch_status_list):
                batch_ids_to_remove.add(batch_id)

            if any(entry["batch_id"] == batch_id for entry in failed_tasks_list):
                batch_ids_to_remove.add(batch_id)

            if batch_id not in active_handlers:
                batch_ids_to_remove.add(batch_id)

        except json.JSONDecodeError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –¥–ª—è batch_id={batch_id}: {e}")

    # ‚úÖ –£–¥–∞–ª—è–µ–º `batch_id` –∏–∑ `available_workers_archive`
    for batch_id in batch_ids_to_remove:
        await redis_client.hdel("available_workers_archive", batch_id)
        logger.debug(f"üóë –£–¥–∞–ª—ë–Ω `batch_id={batch_id}` –∏–∑ `available_workers_archive`")

    logger.info("üèÅ –û—á–∏—Å—Ç–∫–∞ `available_workers_archive` –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")


async def cleanup_batch_results(redis_client, batch_status_list, failed_tasks_list, active_handlers):
    """–£–¥–∞–ª—è–µ—Ç `batch_id` –∏–∑ `batch_results`, –µ—Å–ª–∏ –µ–≥–æ —Å—Ç–∞—Ç—É—Å `success`, –æ–Ω –Ω–µ–∞–∫—Ç–∏–≤–µ–Ω –∏–ª–∏ –∏–º–µ–µ—Ç –æ—à–∏–±–∫–∏."""

    batch_results = await redis_client.hgetall("batch_results")

    if not batch_results:
        logger.info("‚úÖ `batch_results` –ø—É—Å—Ç, –Ω–µ—á–µ–≥–æ —É–¥–∞–ª—è—Ç—å.")
        return

    batch_ids_to_remove = set()

    for batch_id, result_data in batch_results.items():
        try:
            # ‚úÖ –î–µ–∫–æ–¥–∏—Ä—É–µ–º JSON-—Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result_info = json.loads(result_data)

            # ‚úÖ –ü—Ä–æ–≤–µ—Ä—è–µ–º `batch_status_list`: –µ—Å–ª–∏ `success`, —É–¥–∞–ª—è–µ–º
            if any(entry["batch_id"] == batch_id and entry["status"] == "success" for entry in batch_status_list):
                batch_ids_to_remove.add(batch_id)

            # ‚úÖ –ü—Ä–æ–≤–µ—Ä—è–µ–º `failed_tasks_list`: –µ—Å–ª–∏ `batch_id` —Ç–∞–º –µ—Å—Ç—å, —É–¥–∞–ª—è–µ–º
            if any(entry["batch_id"] == batch_id for entry in failed_tasks_list):
                batch_ids_to_remove.add(batch_id)

            # ‚úÖ –ü—Ä–æ–≤–µ—Ä—è–µ–º `active_handlers`: –µ—Å–ª–∏ `batch_id` –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, —É–¥–∞–ª—è–µ–º
            if batch_id not in active_handlers:
                batch_ids_to_remove.add(batch_id)

        except json.JSONDecodeError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –¥–ª—è batch_id={batch_id}: {e}")

    # ‚úÖ –£–¥–∞–ª—è–µ–º `batch_id` –∏–∑ `batch_results`
    for batch_id in batch_ids_to_remove:
        await redis_client.hdel("batch_results", batch_id)
        logger.debug(f"üóë –£–¥–∞–ª—ë–Ω `batch_id={batch_id}` –∏–∑ `batch_results`")

    logger.info("üèÅ –û—á–∏—Å—Ç–∫–∞ `batch_results` –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")



async def cleanup_tick_processed(redis_client, batch_status_list):
    """–£–¥–∞–ª—è–µ—Ç `tick_processed`, –µ—Å–ª–∏ –µ–≥–æ —Å—Ç–∞—Ç—É—Å `done` —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å `success` –≤ `batch_status_list`."""

    tick_processed = await redis_client.hgetall("tick_processed")

    if not tick_processed:
        logger.info("‚úÖ `tick_processed` –ø—É—Å—Ç, –Ω–µ—á–µ–≥–æ —É–¥–∞–ª—è—Ç—å.")
        return

    batch_ids_to_remove = set()

    for tick_key, status in tick_processed.items():
        if status == "done":
            try:
                # ‚úÖ –ü–∞—Ä—Å–∏–º JSON-—á–∞—Å—Ç—å –∫–ª—é—á–∞
                tick_data = json.loads(tick_key.split(",", 1)[1].replace("'", "\""))
                batch_id = tick_data.get("tick_id")  # ‚úÖ –ü–æ–ª—É—á–∞–µ–º `tick_id`
                
                # ‚úÖ –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ `batch_id` –≤ `batch_status_list`
                if any(entry["batch_id"] == batch_id and entry["status"] == "success" for entry in batch_status_list):
                    batch_ids_to_remove.add(tick_key)

            except json.JSONDecodeError as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –≤ tick_key: {tick_key}, {e}")

    # ‚úÖ –£–¥–∞–ª—è–µ–º `tick_processed` –¥–ª—è –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
    for tick_key in batch_ids_to_remove:
        await redis_client.hdel("tick_processed", tick_key)
        logger.debug(f"üóë –£–¥–∞–ª—ë–Ω `tick_processed` ‚Üí {tick_key}")

    logger.info("üèÅ –û—á–∏—Å—Ç–∫–∞ `tick_processed` –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

async def cleanup_processed_batches(redis_client, batch_status_list):
    """–£–¥–∞–ª—è–µ—Ç `batch_id` –∏–∑ `processed_batches`, –µ—Å–ª–∏ –µ–≥–æ —Å—Ç–∞—Ç—É—Å `success`."""

    processed_batches = await redis_client.hgetall("processed_batches")

    if not processed_batches:
        logger.info("‚úÖ `processed_batches` –ø—É—Å—Ç, –Ω–µ—á–µ–≥–æ —É–¥–∞–ª—è—Ç—å.")
        return

    batch_ids_to_remove = {entry["batch_id"] for entry in batch_status_list if entry["status"] == "success"}

    for batch_id in batch_ids_to_remove:
        await redis_client.hdel("processed_batches", batch_id)
        logger.debug(f"üóë –£–¥–∞–ª—ë–Ω `batch_id={batch_id}` –∏–∑ `processed_batches`")

    logger.info(f"üèÅ –û—á–∏—Å—Ç–∫–∞ `processed_batches` –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –£–¥–∞–ª–µ–Ω–æ {len(batch_ids_to_remove)} –∑–∞–ø–∏—Å–µ–π.")


async def cleanup_batch_status(redis_client, batch_status_list):
    """–£–¥–∞–ª—è–µ—Ç `batch_id` –∏–∑ `batch_status`, –µ—Å–ª–∏ –µ–≥–æ —Å—Ç–∞—Ç—É—Å `success`."""
    
    if not batch_status_list:
        logger.info("‚úÖ `batch_status_list` –ø—É—Å—Ç, –æ—á–∏—Å—Ç–∫–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")
        return

    batch_status = await redis_client.hgetall("batch_status")

    if not batch_status:
        logger.info("‚úÖ `batch_status` –ø—É—Å—Ç, –Ω–µ—á–µ–≥–æ —É–¥–∞–ª—è—Ç—å.")
        return

    batch_ids_to_remove = {entry["batch_id"] for entry in batch_status_list if entry["status"] == "success"}

    # ‚úÖ –£–¥–∞–ª—è–µ–º `batch_id` –∏–∑ `batch_status`
    for batch_id in batch_ids_to_remove:
        await redis_client.hdel("batch_status", batch_id)
        logger.debug(f"üóë –£–¥–∞–ª—ë–Ω `batch_id={batch_id}` –∏–∑ `batch_status`")

    logger.info(f"üèÅ –û—á–∏—Å—Ç–∫–∞ `batch_status` –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –£–¥–∞–ª–µ–Ω–æ {len(batch_ids_to_remove)} –∑–∞–ø–∏—Å–µ–π.")


async def cleanup_tick_status(redis_client):
    """–£–¥–∞–ª—è–µ—Ç –∑–∞–ø–∏—Å–∏ `tick_status`, –µ—Å–ª–∏ –æ–Ω–∏ –∏–º–µ—é—Ç —Å—Ç–∞—Ç—É—Å `done`."""
    logger.info("üóë –ó–∞–ø—É—Å–∫–∞–µ–º –æ—á–∏—Å—Ç–∫—É `tick_status`...")

    tick_statuses = await redis_client.hgetall("tick_status")
    if not tick_statuses:
        logger.info("‚úÖ `tick_status` —É–∂–µ –ø—É—Å—Ç, –æ—á–∏—Å—Ç–∫–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")
        return

    for tick_key, status in tick_statuses.items():
        if status == "done":  # üìå –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–µ
            await redis_client.hdel("tick_status", tick_key)
            logger.debug(f"üóë –£–¥–∞–ª–µ–Ω–æ `tick_status`: {tick_key}")
