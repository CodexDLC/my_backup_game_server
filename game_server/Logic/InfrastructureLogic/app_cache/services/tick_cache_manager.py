# game_server/Logic/InfrastructureLogic/app_cache/services/tick_cache_manager.py

import logging
import json
from typing import Any, Dict, List, Optional

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∏–∑–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π –∫–ª–∏–µ–Ω—Ç Redis
from game_server.Logic.InfrastructureLogic.app_cache.central_redis_client import central_redis_client

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã TTL, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –¥–ª—è —Ç–∏–∫–æ–≤
from game_server.Logic.ApplicationLogic.coordinator_tick.constant_tick import (
    BATCH_TASK_TTL_SECONDS
)

logger = logging.getLogger(__name__)

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è –∫–ª—é—á–µ–π Redis, —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è —Ç–∏–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã
REDIS_COORDINATOR_TASK_HASH = "coordinator:tasks" 
REDIS_TASK_QUEUE_EXPLORATION = "exploration" 
REDIS_TASK_QUEUE_TRAINING = "training"     
REDIS_TASK_QUEUE_CRAFTING = "crafting"     


class TickCacheManager:
    """
    –í—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–¥–∞—á–∞–º–∏ —Ç–∏–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –≤ Redis.
    """
    # üî• –ò–ó–ú–ï–ù–ï–ù–ò–ï: –£–ø—Ä–æ—â–∞–µ–º __init__, –∫–∞–∫ –∏ –≤ –¥—Ä—É–≥–∏—Ö –º–µ–Ω–µ–¥–∂–µ—Ä–∞—Ö.
    def __init__(self):
        self.redis = central_redis_client
        logger.info("‚úÖ TickCacheManager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")

    # –í—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ—Å—Ç–∞—é—Ç—Å—è –ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô,
    # —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∏ —É–∂–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç self.redis.

    async def add_batch_of_instructions_to_category(self, category: str, batch_id: str, instructions_batch: List[Dict[str, Any]]):
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç –±–∞—Ç—á –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –ø–æ–¥ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º ID –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–µ –ø–æ–ª–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        –≤ –≥–ª–∞–≤–Ω–æ–º —Ö—ç—à–µ REDIS_COORDINATOR_TASK_HASH.
        """
        if category not in [REDIS_TASK_QUEUE_EXPLORATION, REDIS_TASK_QUEUE_TRAINING, REDIS_TASK_QUEUE_CRAFTING]:
            logger.error(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è –∑–∞–¥–∞—á–∏: {category}")
            return
        
        current_batches_json = await self.redis.hget(REDIS_COORDINATOR_TASK_HASH, category)
        current_batches = json.loads(current_batches_json) if current_batches_json else {}

        current_batches[batch_id] = instructions_batch

        await self.redis.hset(REDIS_COORDINATOR_TASK_HASH, category, json.dumps(current_batches))
        await self.redis.expire(REDIS_COORDINATOR_TASK_HASH, BATCH_TASK_TTL_SECONDS)
        logger.debug(f"TickCacheManager: –î–æ–±–∞–≤–ª–µ–Ω –±–∞—Ç—á '{batch_id}' —Å {len(instructions_batch)} –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏—é '{category}'.")

    async def get_all_categories_with_batches(self) -> Dict[str, Dict[str, List[Dict[str, Any]]]]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ –≤—Å–µ –±–∞—Ç—á–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –¥–ª—è –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ Redis.
        """
        logger.info(f"TickCacheManager: –ù–∞—á–∏–Ω–∞–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Å–µ—Ö –±–∞—Ç—á–µ–π –∏–∑ '{REDIS_COORDINATOR_TASK_HASH}'...")
        
        all_categories_raw = await self.redis.hgetall(REDIS_COORDINATOR_TASK_HASH)
        
        if not all_categories_raw:
            logger.info(f"TickCacheManager: –•—ç—à '{REDIS_COORDINATOR_TASK_HASH}' –ø—É—Å—Ç. –ù–µ—Ç –±–∞—Ç—á–µ–π –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è.")
            return {}
        
        categorized_batches = {}
        for category, batches_json in all_categories_raw.items():
            try:
                batches_for_category = json.loads(batches_json)
                
                if isinstance(batches_for_category, dict):
                    categorized_batches[category] = batches_for_category
                    logger.debug(f"TickCacheManager: –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(batches_for_category)} –±–∞—Ç—á–µ–π –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}'.")
                else:
                    logger.error(f"TickCacheManager: –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}'.")

            except json.JSONDecodeError as e:
                logger.error(f"TickCacheManager: –û—à–∏–±–∫–∞ –¥–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}': {e}")

        logger.info(f"TickCacheManager: –ó–∞–≤–µ—Ä—à–µ–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –±–∞—Ç—á–µ–π –∏–∑ Redis. –í—Å–µ–≥–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å –±–∞—Ç—á–∞–º–∏: {len(categorized_batches)}.")
        return categorized_batches

    async def get_batch_by_id(self, category: str, batch_id: str) -> Optional[List[Dict[str, Any]]]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –±–∞—Ç—á –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –ø–æ –µ–≥–æ ID –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏.
        """
        current_batches_json = await self.redis.hget(REDIS_COORDINATOR_TASK_HASH, category)
        if not current_batches_json:
            logger.debug(f"TickCacheManager: –ö–∞—Ç–µ–≥–æ—Ä–∏—è '{category}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∏–ª–∏ –ø—É—Å—Ç–∞.")
            return None
        
        current_batches = json.loads(current_batches_json)
        batch = current_batches.get(batch_id)
        
        if batch:
            logger.debug(f"TickCacheManager: –ë–∞—Ç—á '{batch_id}' –∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}' —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω.")
        else:
            logger.debug(f"TickCacheManager: –ë–∞—Ç—á '{batch_id}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}'.")
        
        return batch

    async def remove_batch_by_id(self, category: str, batch_id: str):
        """
        –£–¥–∞–ª—è–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –±–∞—Ç—á –ø–æ –µ–≥–æ ID –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏.
        """
        current_batches_json = await self.redis.hget(REDIS_COORDINATOR_TASK_HASH, category)
        if not current_batches_json:
            logger.debug(f"TickCacheManager: –ù–µ—á–µ–≥–æ —É–¥–∞–ª—è—Ç—å, –∫–∞—Ç–µ–≥–æ—Ä–∏—è '{category}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∏–ª–∏ –ø—É—Å—Ç–∞.")
            return
        
        current_batches = json.loads(current_batches_json)
        if batch_id in current_batches:
            del current_batches[batch_id]
            if not current_batches:
                await self.redis.hdel(REDIS_COORDINATOR_TASK_HASH, category)
                logger.info(f"TickCacheManager: –ö–∞—Ç–µ–≥–æ—Ä–∏—è '{category}' —Å—Ç–∞–ª–∞ –ø—É—Å—Ç–æ–π –∏ —É–¥–∞–ª–µ–Ω–∞ –∏–∑ '{REDIS_COORDINATOR_TASK_HASH}'.")
            else:
                await self.redis.hset(REDIS_COORDINATOR_TASK_HASH, category, json.dumps(current_batches))
                logger.debug(f"TickCacheManager: –ë–∞—Ç—á '{batch_id}' —É–¥–∞–ª–µ–Ω –∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}'.")
            
            await self.redis.expire(REDIS_COORDINATOR_TASK_HASH, BATCH_TASK_TTL_SECONDS)
        else:
            logger.debug(f"TickCacheManager: –ë–∞—Ç—á '{batch_id}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}', –Ω–∏—á–µ–≥–æ –Ω–µ —É–¥–∞–ª–µ–Ω–æ.")

    async def delete_all_categorized_tasks(self):
        """
        –£–¥–∞–ª—è–µ—Ç –≤–µ—Å—å —Ö—ç—à —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∑–∞–¥–∞—á–∞–º–∏ –∏–∑ Redis.
        """
        await self.redis.delete(REDIS_COORDINATOR_TASK_HASH)
        logger.info(f"TickCacheManager: –•—ç—à '{REDIS_COORDINATOR_TASK_HASH}' –ø–æ–ª–Ω–æ—Å—Ç—å—é —É–¥–∞–ª–µ–Ω.")

# –°–æ–∑–¥–∞–µ–º –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ Backend'–µ
tick_cache_manager = TickCacheManager()
