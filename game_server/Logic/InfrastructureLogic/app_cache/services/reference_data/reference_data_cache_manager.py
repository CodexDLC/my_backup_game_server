# game_server/Logic/InfrastructureLogic/app_cache/services/reference_data/reference_data_cache_manager.py

import logging
from typing import Dict, Any, List, Optional, Type, Union
import uuid
import msgpack
from datetime import datetime

from game_server.Logic.InfrastructureLogic.app_cache.central_redis_client import CentralRedisClient
from game_server.Logic.InfrastructureLogic.app_cache.interfaces.interfaces_reference_data_cache import IReferenceDataCacheManager
from game_server.config.logging.logging_setup import app_logger as logger
from game_server.Logic.InfrastructureLogic.app_post.repository_manager import RepositoryManager
from game_server.Logic.CoreServices.services.data_version_manager import DataVersionManager # –≠—Ç–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –±—É–¥–µ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –ø–æ–∑–∂–µ
# from game_server.database.models.models import Base # –£–¥–∞–ª—è–µ–º, –µ—Å–ª–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é
# from pydantic import BaseModel # –£–¥–∞–ª—è–µ–º, –µ—Å–ª–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é

from game_server.config.constants.redis_key.reference_data_keys import (
    REDIS_KEY_GENERATOR_ITEM_BASE, REDIS_KEY_GENERATOR_MATERIALS, REDIS_KEY_GENERATOR_SUFFIXES,
    REDIS_KEY_GENERATOR_MODIFIERS, REDIS_KEY_GENERATOR_SKILLS, REDIS_KEY_GENERATOR_BACKGROUND_STORIES,
    REDIS_KEY_GENERATOR_PERSONALITIES,
    REDIS_KEY_WORLD_CONNECTIONS
)

class ReferenceDataCacheManager(IReferenceDataCacheManager):
    def __init__(self, repository_manager: RepositoryManager, redis_client: CentralRedisClient):
        self.repository_manager = repository_manager
        self.redis_client = redis_client
        self.logger = logger
        logger.info("‚úÖ ReferenceDataCacheManager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")

    def _prepare_data_for_msgpack(self, data: Union[Dict[str, Any], List[Any], Any]) -> Union[Dict[str, Any], List[Any], Any]:
        """
        –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç UUID –∏ datetime –æ–±—ä–µ–∫—Ç—ã –≤ —Å–ª–æ–≤–∞—Ä–µ/—Å–ø–∏—Å–∫–µ –≤ —Å—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
        –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å MsgPack.
        """
        if isinstance(data, dict):
            prepared_data = {}
            for k, v in data.items():
                prepared_data[k] = self._prepare_data_for_msgpack(v)
            return prepared_data
        elif isinstance(data, list):
            return [self._prepare_data_for_msgpack(item) for item in data]
        elif isinstance(data, uuid.UUID):
            return str(data)
        elif isinstance(data, datetime):
            return data.isoformat()
        else:
            return data

    async def _perform_caching(self, redis_key: str, data_for_redis: Union[Dict[str, Dict[str, Any]], List[Dict[str, Any]]], model_name: str) -> bool:
        """
        –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ Redis.
        –ü—Ä–∏–Ω–∏–º–∞–µ—Ç –æ–±—ã—á–Ω—ã–µ Python-—Å–ª–æ–≤–∞—Ä–∏, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–ª–æ–∂–Ω—ã–µ —Ç–∏–ø—ã –∏ —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ—Ç –≤ MSGPACK –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è.
        """
        try:
            self.logger.debug(f"DEBUG_PERFORM_CACHING: –ù–∞—á–∏–Ω–∞–µ–º _perform_caching –¥–ª—è {model_name}. redis_key: {redis_key}")
            self.logger.debug(f"DEBUG_PERFORM_CACHING: –¢–∏–ø data_for_redis: {type(data_for_redis)}. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {len(data_for_redis) if hasattr(data_for_redis, '__len__') else 'N/A'}")

            if isinstance(data_for_redis, dict):
                # Prepared mapping —Ç–µ–ø–µ—Ä—å –±—É–¥–µ—Ç —Ö—Ä–∞–Ω–∏—Ç—å —É–∂–µ —É–ø–∞–∫–æ–≤–∞–Ω–Ω—ã–µ –±–∞–π—Ç—ã
                prepared_mapping_for_redis_bytes: Dict[str, bytes] = {}
                list_of_raw_dicts_for_hash = [] # Used for calculating hash before packing

                for key, raw_dict_data in data_for_redis.items():
                    self.logger.debug(f"DEBUG_PERFORM_CACHING_DICT_ITEM: Processing key '{key}' for {model_name}. raw_dict_data type: {type(raw_dict_data)}")
                    self.logger.debug(f"DEBUG_PERFORM_CACHING_DICT_ITEM: raw_dict_data sample: {str(raw_dict_data)[:200]}...")

                    if isinstance(raw_dict_data, dict):
                        list_of_raw_dicts_for_hash.append(raw_dict_data)
                        
                        prepared_dict = self._prepare_data_for_msgpack(raw_dict_data)
                        packed_bytes = msgpack.dumps(prepared_dict, use_bin_type=True)
                        prepared_mapping_for_redis_bytes[key] = packed_bytes
                    else:
                        self.logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –≤ dict-—Ñ–æ—Ä–º–∞—Ç–µ: {type(raw_dict_data)} –¥–ª—è –∫–ª—é—á–∞ '{key}'. –û–∂–∏–¥–∞–ª—Å—è dict.")
                        raise TypeError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö –≤ 'dict' —Ä–µ–∂–∏–º–µ –¥–ª—è '{model_name}' (–∫–ª—é—á: '{key}'): {type(raw_dict_data)}. –û–∂–∏–¥–∞–ª—Å—è dict.")

                entity_hash = DataVersionManager._calculate_data_hash(list_of_raw_dicts_for_hash)
                current_cache_hash = await self.repository_manager.data_versions.get_current_version(model_name)
                
                if entity_hash == current_cache_hash:
                    self.logger.info(f"‚úÖ {model_name} –¥–∞–Ω–Ω—ã–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã –≤ –∫—ç—à–µ (—Ö—ç—à: {entity_hash[:8]}...). –ü—Ä–æ–ø—É—Å–∫.")
                    return True

                self.logger.info(f"üîÑ –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–ª—è {model_name}. –°—Ç–∞—Ä—ã–π —Ö—ç—à: {current_cache_hash[:8] if current_cache_hash else 'N/A'}, –Ω–æ–≤—ã–π: {entity_hash[:8]}....")
                
                hset_success_result = await self.redis_client.hsetall_msgpack(redis_key, prepared_mapping_for_redis_bytes)
                if not hset_success_result: # hsetall_msgpack —Ç–µ–ø–µ—Ä—å –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç bool
                    self.logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –¥–∞–Ω–Ω—ã–µ {model_name} –≤ Redis –ø–æ –∫–ª—é—á—É '{redis_key}'. –†–µ–∑—É–ª—å—Ç–∞—Ç hsetall_msgpack: {hset_success_result}.")
                    raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –¥–∞–Ω–Ω—ã–µ {model_name} –≤ Redis: hsetall_msgpack –≤–µ—Ä–Ω—É–ª {hset_success_result}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Redis.")
                
                await self.repository_manager.data_versions.update_version(model_name, entity_hash)

            elif isinstance(data_for_redis, list):
                list_of_raw_dicts_for_hash = []
                prepared_list_for_msgpack: List[Dict[str, Any]] = []

                for raw_dict_data in data_for_redis:
                    self.logger.debug(f"DEBUG_PERFORM_CACHING_LIST_ITEM: Processing item {raw_dict_data} for {model_name}. raw_dict_data type: {type(raw_dict_data)}")
                    self.logger.debug(f"DEBUG_PERFORM_CACHING_LIST_ITEM: raw_dict_data sample: {str(raw_dict_data)[:200]}...")

                    if isinstance(raw_dict_data, dict):
                        list_of_raw_dicts_for_hash.append(raw_dict_data)
                        
                        prepared_dict = self._prepare_data_for_msgpack(raw_dict_data)
                        prepared_list_for_msgpack.append(prepared_dict)
                    else:
                        self.logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –≤ list-—Ñ–æ—Ä–º–∞—Ç–µ: {type(raw_dict_data)}. –û–∂–∏–¥–∞–ª—Å—è dict.")
                        raise TypeError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö –≤ 'list' —Ä–µ–∂–∏–º–µ –¥–ª—è '{model_name}': {type(raw_dict_data)}. –û–∂–∏–¥–∞–ª—Å—è dict.")
                
                entity_hash = DataVersionManager._calculate_data_hash(prepared_list_for_msgpack)
                current_cache_hash = await self.repository_manager.data_versions.get_current_version(model_name)

                if entity_hash == current_cache_hash:
                    self.logger.info(f"‚úÖ {model_name} –¥–∞–Ω–Ω—ã–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã –≤ –∫—ç—à–µ (—Ö—ç—à: {entity_hash[:8]}...). –ü—Ä–æ–ø—É—Å–∫.")
                    return True
                
                self.logger.info(f"üîÑ –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–ª—è {model_name}. –°—Ç–∞—Ä—ã–π —Ö—ç—à: {current_cache_hash[:8] if current_cache_hash else 'N/A'}, –Ω–æ–≤—ã–π: {entity_hash[:8]}....")
                
                packed_bytes = msgpack.dumps(prepared_list_for_msgpack, use_bin_type=True)
                set_success_result = await self.redis_client.set_msgpack(redis_key, packed_bytes)
                if not set_success_result: # set_msgpack —Ç–µ–ø–µ—Ä—å –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç bool
                    self.logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –¥–∞–Ω–Ω—ã–µ {model_name} –≤ Redis –ø–æ –∫–ª—é—á—É '{redis_key}'. –†–µ–∑—É–ª—å—Ç–∞—Ç set_msgpack: {set_success_result}")
                    raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –¥–∞–Ω–Ω—ã–µ {model_name} –≤ Redis: set_msgpack –≤–µ—Ä–Ω—É–ª {set_success_result}.")

                await self.repository_manager.data_versions.update_version(model_name, entity_hash)
            
            else:
                self.logger.error(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è: {type(data_for_redis)}")
                raise TypeError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è '{model_name}': {type(data_for_redis)}")

            self.logger.info(f"‚úÖ {model_name} –¥–∞–Ω–Ω—ã–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω—ã –≤ Redis –ø–æ –∫–ª—é—á—É '{redis_key}'.")
            return True
        except Exception as e:
            self.logger.critical(f"üö® –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–∏ {model_name} –¥–∞–Ω–Ω—ã—Ö: {e}", exc_info=True)
            raise

    # üî• –ù–û–í–´–ô –ú–ï–¢–û–î –î–õ–Ø –ß–¢–ï–ù–ò–Ø –ö–≠–®–ò–†–û–í–ê–ù–ù–´–• –î–ê–ù–ù–´–• –ò–ó REDIS (–ò—Å–ø–æ–ª—å–∑—É–µ—Ç MsgPack)
    async def get_cached_data(self, redis_key: str, is_hash_data: bool = True) -> Optional[Union[Dict[str, Any], List[Any]]]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ Redis, –∏—Å–ø–æ–ª—å–∑—É—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ MsgPack –º–µ—Ç–æ–¥—ã.
        :param redis_key: –ö–ª—é—á Redis.
        :param is_hash_data: True, –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ —Ö—Ä–∞–Ω—è—Ç—Å—è –∫–∞–∫ HASH, False, –µ—Å–ª–∏ –∫–∞–∫ STRING (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é True).
        :return: –î–µ—Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–ª–∏ None.
        """
        self.logger.debug(f"–ü–æ–ª—É—á–µ–Ω–∏–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª—é—á–∞ '{redis_key}'. –¢–∏–ø: {'HASH' if is_hash_data else 'STRING'}.")
        try:
            if is_hash_data:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º hgetall_msgpack –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤—Å–µ—Ö –ø–æ–ª–µ–π —Ö—ç—à–∞
                cached_data = await self.redis_client.hgetall_msgpack(redis_key)
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º get_msgpack –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                cached_data = await self.redis_client.get_msgpack(redis_key)
            
            if cached_data:
                self.logger.debug(f"–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è '{redis_key}' –Ω–∞–π–¥–µ–Ω—ã.")
            else:
                self.logger.debug(f"–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è '{redis_key}' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –ø—É—Å—Ç—ã.")
            return cached_data
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª—é—á–∞ '{redis_key}': {e}", exc_info=True)
            return None


    async def _cache_from_db_with_version_check(self, repo_obj: Any, redis_key: str, pk_name: str, model_name: str) -> bool:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î, –∫—ç—à–∏—Ä—É–µ—Ç –∏—Ö –≤ Redis –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –≤–µ—Ä—Å–∏—é.
        –î–∞–Ω–Ω—ã–µ –∏–∑ –ë–î —Ç–∞–∫–∂–µ –±—É–¥—É—Ç –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω—ã –¥–ª—è MsgPack.
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–ø–µ—Ä—å –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º —É—Ä–æ–≤–Ω–µ (INFO/DEBUG), –±–µ–∑ –ª–∏—à–Ω–∏—Ö CRITICAL.
        """
        try:
            self.logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ {model_name} –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î...")
            all_orm_entities = await repo_obj.get_all()
            
            self.logger.debug(f"–î–ª—è {model_name}: –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(all_orm_entities)} ORM-—Å—É—â–Ω–æ—Å—Ç–µ–π –∏–∑ –ë–î.")
            if not all_orm_entities:
                self.logger.warning(f"–î–ª—è {model_name}: all_orm_entities –ø—É—Å—Ç. –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è.")
                return True 

            data_for_redis_raw: Dict[str, Dict[str, Any]] = {}
            list_of_raw_dicts_for_hash = []

            for entity in all_orm_entities:
                self.logger.debug(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—É—â–Ω–æ—Å—Ç–∏ {model_name}. –¢–∏–ø –æ–±—ä–µ–∫—Ç–∞ ORM: {type(entity)}")
                if not hasattr(entity, 'to_dict') or not callable(getattr(entity, 'to_dict')):
                    self.logger.error(f"ORM-—Å—É—â–Ω–æ—Å—Ç—å {type(entity)} –Ω–µ –∏–º–µ–µ—Ç callable –º–µ—Ç–æ–¥–∞ 'to_dict()'")
                    raise AttributeError(f"ORM-—Å—É—â–Ω–æ—Å—Ç—å {type(entity)} –Ω–µ –∏–º–µ–µ—Ç callable –º–µ—Ç–æ–¥–∞ 'to_dict()'")
                
                raw_dict_from_orm = entity.to_dict()
                
                self.logger.debug(f"{model_name} raw_dict_from_orm —Ç–∏–ø: {type(raw_dict_from_orm)}")
                self.logger.debug(f"{model_name} raw_dict_from_orm –ø—Ä–∏–º–µ—Ä: {str(raw_dict_from_orm)[:500]}...")

                if not isinstance(raw_dict_from_orm, dict) or not raw_dict_from_orm:
                    self.logger.warning(f"{model_name}: to_dict() –≤–µ—Ä–Ω—É–ª –Ω–µ —Å–ª–æ–≤–∞—Ä—å –∏–ª–∏ –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å: {raw_dict_from_orm}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–ø–∏—Å—å.")
                    continue 

                list_of_raw_dicts_for_hash.append(raw_dict_from_orm)
                
                prepared_dict = self._prepare_data_for_msgpack(raw_dict_from_orm)
                
                self.logger.debug(f"{model_name} prepared_dict —Ç–∏–ø: {type(prepared_dict)}")
                self.logger.debug(f"{model_name} prepared_dict –ø—Ä–∏–º–µ—Ä: {str(prepared_dict)[:500]}...")

                pk_value = getattr(entity, pk_name)
                if not pk_value:
                    self.logger.warning(f"–î–ª—è {model_name}: –ó–Ω–∞—á–µ–Ω–∏–µ PK ('{pk_name}') –¥–ª—è —Å—É—â–Ω–æ—Å—Ç–∏ {entity} –ø—É—Å—Ç–æ–µ –∏–ª–∏ None. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                    continue 

                data_for_redis_raw[str(pk_value)] = prepared_dict
            
            self.logger.debug(f"–î–ª—è {model_name}: data_for_redis_raw —Å–æ–¥–µ—Ä–∂–∏—Ç {len(data_for_redis_raw)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤.")
            if not data_for_redis_raw:
                self.logger.warning(f"–î–ª—è {model_name}: data_for_redis_raw –ø—É—Å—Ç –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—Å–µ—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π. –≠—Ç–æ –ø—Ä–∏–≤–µ–¥–µ—Ç –∫ hsetall_msgpack: 0.")
                return True 

            entity_hash = DataVersionManager._calculate_data_hash(list_of_raw_dicts_for_hash)
            current_cache_hash = await self.repository_manager.data_versions.get_current_version(model_name)
            
            if entity_hash == current_cache_hash:
                self.logger.info(f"‚úÖ {model_name} –¥–∞–Ω–Ω—ã–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã –≤ –∫—ç—à–µ (—Ö—ç—à: {entity_hash[:8]}...). –ü—Ä–æ–ø—É—Å–∫.")
                return True

            self.logger.info(f"üîÑ –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–ª—è {model_name}. –°—Ç–∞—Ä—ã–π —Ö—ç—à: {current_cache_hash[:8] if current_cache_hash else 'N/A'}, –Ω–æ–≤—ã–π: {entity_hash[:8]}....")
            
            # –ú—ã –æ–∂–∏–¥–∞–µ–º, —á—Ç–æ data_for_redis_raw - —ç—Ç–æ —É–∂–µ Dict[str, Dict[str, Any]],
            # –≥–¥–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ dict'—ã —É–∂–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã _prepare_data_for_msgpack
            # –∏ –±—É–¥—É—Ç —É–ø–∞–∫–æ–≤–∞–Ω—ã –≤ msgpack.dumps –¥–ª—è hsetall_msgpack.
            
            # üî• –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü–µ—Ä–µ–¥–∞–µ–º hsetall_msgpack –≥–æ—Ç–æ–≤—ã–π dict[str, bytes]
            # –£–ø–∞–∫–æ–≤–∫–∞ –≤ msgpack.dumps –¥–æ–ª–∂–Ω–∞ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç—å –∑–¥–µ—Å—å
            final_mapping_for_hset = {
                k: msgpack.dumps(v, use_bin_type=True) for k, v in data_for_redis_raw.items()
            }

            hset_success_result = await self.redis_client.hsetall_msgpack(redis_key, final_mapping_for_hset)
            
            if not hset_success_result:
                self.logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –¥–∞–Ω–Ω—ã–µ {model_name} –≤ Redis –ø–æ –∫–ª—é—á—É '{redis_key}'. –†–µ–∑—É–ª—å—Ç–∞—Ç hsetall_msgpack: {hset_success_result}. –í–µ—Ä–æ—è—Ç–Ω–æ, –æ—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å Redis –∏–ª–∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞.")
                raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –¥–∞–Ω–Ω—ã–µ {model_name} –≤ Redis: hsetall_msgpack –≤–µ—Ä–Ω—É–ª {hset_success_result}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Redis.")
            
            # –õ–æ–≥–∏–∫–∞ –¥–ª—è hset_success_result (–±—ã–ª True/False)
            if not hset_success_result: # –ï—Å–ª–∏ hsetall_msgpack –≤–µ—Ä–Ω—É–ª False
                self.logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –¥–∞–Ω–Ω—ã–µ {model_name} –≤ Redis –ø–æ –∫–ª—é—á—É '{redis_key}'. –†–µ–∑—É–ª—å—Ç–∞—Ç hsetall_msgpack: {hset_success_result}.")
                raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –¥–∞–Ω–Ω—ã–µ {model_name} –≤ Redis: hsetall_msgpack –≤–µ—Ä–Ω—É–ª {hset_success_result}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Redis.")
            elif isinstance(hset_success_result, int) and hset_success_result == 0 and len(final_mapping_for_hset) > 0: # –≠—Ç–æ –Ω–µ –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç, –µ—Å–ª–∏ hsetall_msgpack –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç bool
                self.logger.info(f"‚úÖ {model_name} –¥–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã –≤ –∫—ç—à–µ Redis –ø–æ –∫–ª—é—á—É '{redis_key}' (–≤—Å–µ –ø–æ–ª—è —É–∂–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª–∏).")
            elif isinstance(hset_success_result, int) and hset_success_result > 0: # –≠—Ç–æ –Ω–µ –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç, –µ—Å–ª–∏ hsetall_msgpack –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç bool
                self.logger.info(f"‚úÖ {model_name} –¥–∞–Ω–Ω—ã–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω—ã –≤ Redis –ø–æ –∫–ª—é—á—É '{redis_key}'. –î–æ–±–∞–≤–ª–µ–Ω–æ –Ω–æ–≤—ã—Ö –ø–æ–ª–µ–π: {hset_success_result}.")
            else: # –≠—Ç–æ –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç, –µ—Å–ª–∏ hsetall_msgpack –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç True
                self.logger.info(f"‚úÖ {model_name} –¥–∞–Ω–Ω—ã–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω—ã –≤ Redis –ø–æ –∫–ª—é—á—É '{redis_key}'.")


            await self.repository_manager.data_versions.update_version(model_name, entity_hash)
            return True # –í—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º True –ø—Ä–∏ —É—Å–ø–µ—Ö–µ
        
        except Exception as e:
            self.logger.critical(f"üö® –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–∏ {model_name} –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î: {e}", exc_info=True)
            raise 


    async def _cache_item_base_from_yaml(self) -> bool:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç ItemBase –¥–∞–Ω–Ω—ã–µ –∏–∑ YAML-—Ñ–∞–π–ª–æ–≤.
        –û–∂–∏–¥–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π –∏–∑ ItemBaseLoader.
        """
        try:
            self.logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ ItemBase –¥–∞–Ω–Ω—ã—Ö (–∏–∑ YAML)...")
            from game_server.Logic.ApplicationLogic.start_orcestrator.coordinator_pre_start.load_seeds.generic_redis.item_base_loader import ItemBaseLoader
            
            item_base_loader_instance = ItemBaseLoader()
            item_bases_data: List[Dict[str, Any]] = await item_base_loader_instance.load_all() 

            self.logger.info(f"DEBUG: ItemBaseLoader.load_all() –≤–µ—Ä–Ω—É–ª {len(item_bases_data)} —Å—ã—Ä—ã—Ö —Å–ª–æ–≤–∞—Ä–µ–π.")

            if not item_bases_data:
                self.logger.warning("‚ö†Ô∏è ItemBaseLoader –Ω–µ –≤–µ—Ä–Ω—É–ª –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ ItemBase.")
                return True

            temp_data_dict_of_raw_dicts = {}
            missing_item_code_count = 0
            empty_item_code_count = 0
            non_string_item_code_count = 0

            for idx, raw_dict_data in enumerate(item_bases_data):
                if not isinstance(raw_dict_data, dict):
                    self.logger.warning(f"‚ö†Ô∏è –≠–ª–µ–º–µ–Ω—Ç –ø–æ –∏–Ω–¥–µ–∫—Å—É {idx} –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º. –≠–ª–µ–º–µ–Ω—Ç: {raw_dict_data}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                    continue

                item_code_value = raw_dict_data.get('item_code')
                
                if item_code_value is None:
                    missing_item_code_count += 1
                    self.logger.warning(f"‚ö†Ô∏è –°–ª–æ–≤–∞—Ä—å –ø–æ –∏–Ω–¥–µ–∫—Å—É {idx} –Ω–µ –∏–º–µ–µ—Ç –∫–ª—é—á–∞ 'item_code' –∏–ª–∏ –µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏–µ None. –°–ª–æ–≤–∞—Ä—å: {raw_dict_data}")
                    continue

                if not isinstance(item_code_value, str):
                    non_string_item_code_count += 1
                    self.logger.warning(f"‚ö†Ô∏è –°–ª–æ–≤–∞—Ä—å –ø–æ –∏–Ω–¥–µ–∫—Å—É {idx} –∏–º–µ–µ—Ç 'item_code' –Ω–µ —Å—Ç—Ä–æ–∫–æ–≤–æ–≥–æ —Ç–∏–ø–∞ ({type(item_code_value)}). –ó–Ω–∞—á–µ–Ω–∏–µ: {item_code_value}. –°–ª–æ–≤–∞—Ä—å: {raw_dict_data}")
                    continue

                if item_code_value == "":
                    empty_item_code_count += 1
                    self.logger.warning(f"‚ö†Ô∏è –°–ª–æ–≤–∞—Ä—å –ø–æ –∏–Ω–¥–µ–∫—Å—É {idx} –∏–º–µ–µ—Ç –ø—É—Å—Ç–æ–π 'item_code'. –°–ª–æ–≤–∞—Ä—å: {raw_dict_data}")
                    continue
                
                temp_data_dict_of_raw_dicts[item_code_value] = raw_dict_data
            
            data_dict_of_item_data = temp_data_dict_of_raw_dicts # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–æ –¥–ª—è —è—Å–Ω–æ—Å—Ç–∏
            
            if missing_item_code_count > 0 or empty_item_code_count > 0 or non_string_item_code_count > 0:
                self.logger.warning(
                    f"‚ö†Ô∏è –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤–∞—Ä–µ–π, –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∏–∑-–∑–∞ –ø—Ä–æ–±–ª–µ–º —Å 'item_code': "
                    f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á: {missing_item_code_count}, "
                    f"–ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞: {empty_item_code_count}, "
                    f"–ù–µ—Å—Ç—Ä–æ–∫–æ–≤—ã–π —Ç–∏–ø: {non_string_item_code_count}."
                )
            
            self.logger.info(f"DEBUG: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤–∞—Ä–µ–π —Å –≤–∞–ª–∏–¥–Ω—ã–º 'item_code' –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è: {len(data_dict_of_item_data)}")

            if not data_dict_of_item_data:
                self.logger.critical("üö® –í—Å–µ ItemBaseData —Å–ª–æ–≤–∞—Ä–∏ –±—ã–ª–∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã –∏–∑-–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –∏–ª–∏ –Ω–µ–≤–∞–ª–∏–¥–Ω–æ–≥–æ 'item_code'. –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≤–∞–ª–µ–Ω–æ.")
                return False

            return await self._perform_caching(REDIS_KEY_GENERATOR_ITEM_BASE, data_dict_of_item_data, "ItemBase")

        except Exception as e:
            self.logger.critical(f"üö® –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–∏ ItemBase –¥–∞–Ω–Ω—ã—Ö: {e}", exc_info=True)
            raise # –ü–µ—Ä–µ–≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ

    async def _cache_location_connections_from_yaml(self) -> bool:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–≤—è–∑–∏ –º–µ–∂–¥—É –ª–æ–∫–∞—Ü–∏—è–º–∏ –∏–∑ YAML-—Ñ–∞–π–ª–æ–≤ –∏ –∫—ç—à–∏—Ä—É–µ—Ç –∏—Ö –≤ Redis.
        –¢–µ–ø–µ—Ä—å –æ–∂–∏–¥–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π –∏–∑ LocationConnectionsLoader.
        """
        try:
            self.logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ Location Connections (–∏–∑ YAML)...")
            from game_server.Logic.ApplicationLogic.start_orcestrator.coordinator_pre_start.load_seeds.generic_redis.location_connections_loader import LocationConnectionsLoader
            
            connections_loader_instance = LocationConnectionsLoader()
            connections_data_list: List[Dict[str, Any]] = await connections_loader_instance.load_all() 
            
            return await self._perform_caching(REDIS_KEY_WORLD_CONNECTIONS, connections_data_list, "LocationConnections")
        except Exception as e:
            self.logger.critical(f"üö® –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–∏ Location Connections: {e}", exc_info=True)
            raise # –ü–µ—Ä–µ–≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ

    # --- –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ ---

    async def cache_all_reference_data(self) -> bool:
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –∑–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö —Å–ø—Ä–∞–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
        """
        self.logger.info("üöÄ –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è —Å–ø—Ä–∞–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        
        cache_operations_status: Dict[str, bool] = {}

        # 1. –ö—ç—à–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ YAML
        yaml_caching_tasks = {
            "ItemBase": self._cache_item_base_from_yaml,
            "LocationConnections": self._cache_location_connections_from_yaml
        }
        for name, task in yaml_caching_tasks.items():
            try:
                status = await task()
                cache_operations_status[name] = status
                if not status:
                    self.logger.critical(f"üö® –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ {name} –ø—Ä–æ–≤–∞–ª–µ–Ω–æ. –ü—Ä–æ—Ü–µ—Å—Å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")
                    raise RuntimeError(f"–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ {name} –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—å –Ω–µ—É–¥–∞—á–µ–π.")
            except Exception as e:
                self.logger.critical(f"üö® –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö {name} –∏–∑ YAML: {e}", exc_info=True)
                raise


        # 2. –ö—ç—à–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î
        data_to_cache_from_db_config = [
            (self.repository_manager.background_stories, REDIS_KEY_GENERATOR_BACKGROUND_STORIES, "name", "BackgroundStory", True), # is_hash_data = True
            (self.repository_manager.materials, REDIS_KEY_GENERATOR_MATERIALS, "material_code", "Material", True),
            (self.repository_manager.modifier_library, REDIS_KEY_GENERATOR_MODIFIERS, "modifier_code", "ModifierLibrary", True),
            (self.repository_manager.personalities, REDIS_KEY_GENERATOR_PERSONALITIES, "name", "Personality", True),
            (self.repository_manager.skills, REDIS_KEY_GENERATOR_SKILLS, "skill_key", "Skill", True),
            (self.repository_manager.suffixes, REDIS_KEY_GENERATOR_SUFFIXES, "suffix_code", "Suffix", True),
            # (self.repository_manager.game_locations, REDIS_KEY_FOR_GAME_LOCATIONS, "access_key", "GameLocation", True),
        ]

        for repo_obj, redis_key, pk_name, model_name, is_hash_data in data_to_cache_from_db_config:
            try:
                status = await self._cache_from_db_with_version_check(repo_obj, redis_key, pk_name, model_name)
                cache_operations_status[model_name] = status
                if not status:
                    self.logger.critical(f"üö® –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ {model_name} –ø—Ä–æ–≤–∞–ª–µ–Ω–æ. –ü—Ä–æ—Ü–µ—Å—Å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")
                    raise RuntimeError(f"–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ {model_name} –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—å –Ω–µ—É–¥–∞—á–µ–π.")
            except Exception as e:
                self.logger.critical(f"üö® –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö {model_name} –∏–∑ –ë–î: {e}", exc_info=True)
                raise


        self.logger.info("‚úÖ –í—Å–µ —Å–ø—Ä–∞–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∫—ç—à–∏—Ä–æ–≤–∞–Ω—ã.")
        return True