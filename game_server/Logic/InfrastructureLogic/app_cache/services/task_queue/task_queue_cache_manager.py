import logging
import json
import time
from typing import Any, Dict, List, Optional, Tuple
from abc import ABC, abstractmethod # Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¾

from game_server.Logic.InfrastructureLogic.app_cache.central_redis_client import CentralRedisClient
from game_server.config.settings.redis_setting import DEFAULT_TTL_TASK_STATUS

# ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ‹Ð¹ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚ RedisBatchStore (Ñ‚ÐµÐ¿ÐµÑ€ÑŒ Ð² Ñ‚Ð¾Ð¹ Ð¶Ðµ Ð¿Ð°Ð¿ÐºÐµ)
from .redis_batch_store import RedisBatchStore # Ð˜Ð·Ð¼ÐµÐ½ÐµÐ½Ð¾

# ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ‹Ð¹ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚ Ð»Ð¾Ð³Ð³ÐµÑ€Ð°
from game_server.Logic.InfrastructureLogic.logging.logging_setup import app_logger as logger # Ð˜Ð·Ð¼ÐµÐ½ÐµÐ½Ð¾

# Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð½Ð¾Ð²Ñ‹Ð¹ Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹Ñ
from game_server.Logic.InfrastructureLogic.app_cache.interfaces.interfaces_task_queue_cache import ITaskQueueCacheManager # Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¾

# Ð˜Ð·Ð¼ÐµÐ½ÑÐµÐ¼ ÐºÐ»Ð°ÑÑ TaskQueueCacheManager, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¾Ð½ Ð½Ð°ÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð» Ð¾Ñ‚ ITaskQueueCacheManager
class TaskQueueCacheManager(ITaskQueueCacheManager): # Ð˜Ð·Ð¼ÐµÐ½ÐµÐ½Ð¾
    """
    Ð’Ñ‹ÑÐ¾ÐºÐ¾ÑƒÑ€Ð¾Ð²Ð½ÐµÐ²Ñ‹Ð¹ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€ Ð´Ð»Ñ ÐºÑÑˆÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¸ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð·Ð°Ð´Ð°Ñ‡Ð°Ð¼Ð¸ Ð¸ Ð¸Ñ… ÑÑ‚Ð°Ñ‚ÑƒÑÐ°Ð¼Ð¸ Ð² Redis.
    Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ RedisBatchStore Ð´Ð»Ñ Ð½Ð¸Ð·ÐºÐ¾ÑƒÑ€Ð¾Ð²Ð½ÐµÐ²Ñ‹Ñ… Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ð¹ Ñ Ð±Ð°Ñ‚Ñ‡Ð°Ð¼Ð¸.
    """
    def __init__(self, redis_client: CentralRedisClient):
        self.redis_batch_store = RedisBatchStore(redis_client)
        self.logger = logger # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ app_logger
        logger.info("âœ… TaskQueueCacheManager Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½.")

    async def add_task_to_queue(self, batch_id: str, key_template: str, specs: List[Dict[str, Any]],
                                 target_count: int, initial_status: str = "pending") -> bool:
        redis_task_key = key_template.format(batch_id=batch_id)
        task_data = {
            "specs": specs,
            "status": initial_status,
            "target_count_in_chunk": target_count,
            "generated_count_in_chunk": 0,
            "timestamp": int(time.time())
        }

        success = await self.redis_batch_store.save_batch(
            key_template=key_template,
            batch_id=batch_id,
            batch_data=task_data,
            ttl_seconds=DEFAULT_TTL_TASK_STATUS
        )

        if success:
            self.logger.info(f"ðŸ’¾ Ð—Ð°Ð´Ð°Ñ‡Ð° '{batch_id}' Ñ {len(specs)} ÑÐ¿ÐµÑ†Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸ÑÐ¼Ð¸ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð° Ð² Ð¾Ñ‡ÐµÑ€ÐµÐ´ÑŒ Redis (Ñ‡ÐµÑ€ÐµÐ· RedisBatchStore).")
            await self.update_task_status(
                batch_id=batch_id, key_template=key_template, status=initial_status, log_prefix=f"TASK({batch_id}):"
            )
            return True
        else:
            self.logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: RedisBatchStore.save_batch Ð²ÐµÑ€Ð½ÑƒÐ» False Ð´Ð»Ñ Ð±Ð°Ñ‚Ñ‡Ð° '{batch_id}'.")
            return False

    async def get_task_batch_specs(self, batch_id: str, key_template: str, log_prefix: str) -> Optional[List[Dict[str, Any]]]:
        loaded_data = await self.redis_batch_store.load_batch(key_template=key_template, batch_id=batch_id)

        if not loaded_data:
            self.logger.error(f"{log_prefix} Ð—Ð°Ð´Ð°Ñ‡Ð¸ Ñ ID {batch_id} (ÐºÐ»ÑŽÑ‡: {key_template.format(batch_id=batch_id)}) Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð° Ð² Redis (Ñ‡ÐµÑ€ÐµÐ· RedisBatchStore).")
            await self.update_task_status(
                batch_id=batch_id, key_template=key_template, status="failed",
                log_prefix=log_prefix, error_message="Batch specs not found (via RedisBatchStore)"
            )
            return None

        specs_obj = loaded_data.get('specs')
        target_count = loaded_data.get('target_count_in_chunk', 0)

        if specs_obj is None:
            self.logger.error(f"{log_prefix} ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ 'specs' Ð² Ð·Ð°Ð´Ð°Ñ‡Ðµ {batch_id}.")
            await self.update_task_status(
                batch_id=batch_id, key_template=key_template, status="failed",
                log_prefix=log_prefix, error_message="Missing specs"
            )
            return None

        batch_specs = specs_obj
        self.logger.info(f"{log_prefix} ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¾ {len(batch_specs)} ÑÐ¿ÐµÑ†Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¹ (Ñ‡ÐµÑ€ÐµÐ· RedisBatchStore).")

        await self.update_task_status(
            batch_id=batch_id, key_template=key_template,
            status="in_progress", log_prefix=log_prefix
        )
        return batch_specs

    async def update_task_status(self, batch_id: str, key_template: str, status: str, log_prefix: str,
                                 error_message: Optional[str] = None, ttl_seconds: Optional[int] = None,
                                 final_generated_count: Optional[int] = None) -> None:
        fields_to_update = {"status": status}
        if error_message:
            fields_to_update["error_message"] = error_message

        if final_generated_count is not None:
            fields_to_update["generated_count_in_chunk"] = final_generated_count

        final_ttl = ttl_seconds if ttl_seconds is not None else DEFAULT_TTL_TASK_STATUS

        await self.redis_batch_store.update_fields(
            key_template=key_template,
            batch_id=batch_id,
            fields=fields_to_update,
            ttl_seconds=final_ttl if status in ["completed", "completed_with_warnings", "failed"] else None
        )
        self.logger.info(f"{log_prefix} Ð¡Ñ‚Ð°Ñ‚ÑƒÑ Ð·Ð°Ð´Ð°Ñ‡Ð¸ '{batch_id}' Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½ Ð½Ð° '{status}' (Ñ‡ÐµÑ€ÐµÐ· RedisBatchStore).")

    async def get_character_task_specs(self, batch_id: str, key_template: str) -> Tuple[Optional[List], int, Optional[str]]:
        log_prefix = f"CHAR_SPEC_GET({batch_id}):"
        loaded_data = await self.redis_batch_store.load_batch(key_template=key_template, batch_id=batch_id)

        if not loaded_data:
            return None, 0, f"Ð—Ð°Ð´Ð°Ñ‡Ð° Ñ ÐºÐ»ÑŽÑ‡Ð¾Ð¼ {key_template.format(batch_id=batch_id)} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð° (Ñ‡ÐµÑ€ÐµÐ· RedisBatchStore)."

        specs_obj = loaded_data.get('specs')
        target_count = loaded_data.get('target_count_in_chunk', 0)

        if specs_obj is None:
            error_msg = f"ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ 'specs' Ð² Ð·Ð°Ð´Ð°Ñ‡Ðµ {key_template.format(batch_id=batch_id)} (Ñ‡ÐµÑ€ÐµÐ· RedisBatchStore)."
            await self.set_character_task_final_status(
                batch_id=batch_id, key_template=key_template,
                status="failed", error_message=error_msg
            )
            return None, target_count, error_msg

        return specs_obj, target_count, None


    async def increment_task_generated_count(self, batch_id: str, key_template: str, increment_by: int = 1) -> Optional[int]:
        return await self.redis_batch_store.increment_field(
            key_template=key_template,
            batch_id=batch_id,
            field="generated_count_in_chunk",
            increment_by=increment_by
        )

    async def set_character_task_final_status(self, batch_id: str, key_template: str, status: str, **kwargs):
        fields_to_update = {"status": status}

        if status == "completed":
            final_count = kwargs.get('final_generated_count')
            target_count = kwargs.get('target_count')
            fields_to_update["generated_count_in_chunk"] = final_count
            if kwargs.get('was_empty'):
                fields_to_update["notes"] = "Batch was empty and processed as completed."
            elif final_count is not None and target_count is not None and final_count < target_count:
                fields_to_update["notes"] = "Completed with some specifications skipped or failed."

        elif status == "failed" and kwargs.get('error_message'):
            fields_to_update["error_message"] = str(kwargs['error_message'])[:1024]

        try:
            await self.redis_batch_store.update_fields(
                key_template=key_template,
                batch_id=batch_id,
                fields=fields_to_update,
                ttl_seconds=DEFAULT_TTL_TASK_STATUS if status in ["completed", "completed_with_warnings", "failed"] else None
            )
        except Exception as e:
            self.logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ð¸ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ ÑÑ‚Ð°Ñ‚ÑƒÑÐ° Ð±Ð°Ñ‚Ñ‡Ð° '{batch_id}': {e}", exc_info=True)

# Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð³Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÑÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€
# task_queue_cache_manager: Optional['TaskQueueCacheManager'] = None